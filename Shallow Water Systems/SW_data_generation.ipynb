{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Third-party library imports\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_to_y(X): # averaging in 2*2 windows (4 pixels)\n",
    "    dim = X.shape[0]\n",
    "    dim = 20\n",
    "    Y = np.zeros((int(dim/2),int(dim/2)))\n",
    "    for i in range(int(dim/2)):\n",
    "        for j in range(int(dim/2)):\n",
    "            Y[i,j] = X[2*i,2*j] + X[2*i+1,2*j] + X[2*i,2*j+1] + X[2*i+1,2*j+1]\n",
    "\n",
    "            Y_noise = np.random.multivariate_normal(np.zeros(100),0.0000 * np.eye(100))\n",
    "            Y_noise.shape = (10,10)\n",
    "            Y = Y + Y_noise\n",
    "    return Y\n",
    "\n",
    "\n",
    "class shallow(object):\n",
    "\n",
    "    time = 0\n",
    "\n",
    "    plt = []\n",
    "    fig = []\n",
    "\n",
    "\n",
    "    def __init__(self, x=[],y=[],h_ini = 1.,u=[],v = [],dx=0.01,dt=0.0001, N=64,L=1., px=16, py=16, R=64, Hp=0.1, g=1., b=0.): # How define no default argument before?\n",
    "\n",
    "\n",
    "        # add a perturbation in pressure surface\n",
    "\n",
    "\n",
    "        self.px, self.py = px, py\n",
    "        self.R = R\n",
    "        self.Hp = Hp\n",
    "\n",
    "\n",
    "\n",
    "        # Physical parameters\n",
    "\n",
    "        self.g = g\n",
    "        self.b = b\n",
    "        self.L=L\n",
    "        self.N=N\n",
    "\n",
    "        self.dx=dx\n",
    "        self.dt=dt\n",
    "\n",
    "        self.x,self.y = np.mgrid[:self.N,:self.N]\n",
    "\n",
    "        self.u=np.zeros((self.N,self.N))\n",
    "        self.v=np.zeros((self.N,self.N))\n",
    "\n",
    "        self.h_ini=h_ini\n",
    "\n",
    "        self.h=self.h_ini * np.ones((self.N,self.N))\n",
    "\n",
    "        rr = (self.x-px)**2 + (self.y-py)**2\n",
    "        self.h[rr<R] = self.h_ini + Hp #set initial conditions\n",
    "\n",
    "        self.lims = [(self.h_ini-self.Hp,self.h_ini+self.Hp),(-0.02,0.02),(-0.02,0.02)]\n",
    "\n",
    "\n",
    "\n",
    "    def dxy(self, A, axis=0):\n",
    "        \"\"\"\n",
    "        Compute derivative of array A using balanced finite differences\n",
    "        Axis specifies direction of spatial derivative (d/dx or d/dy)\n",
    "        dA[i]/dx =  (A[i+1] - A[i-1] )  / 2dx\n",
    "        \"\"\"\n",
    "        return (np.roll(A, -1, axis) - np.roll(A, 1, axis)) / (self.dx*2.) # roll: shift the array axis=0 shift the horizontal axis\n",
    "\n",
    "    def d_dx(self, A):\n",
    "        return self.dxy(A,1)\n",
    "\n",
    "    def d_dy(self, A):\n",
    "        return self.dxy(A,0)\n",
    "\n",
    "\n",
    "    def d_dt(self, h, u, v):\n",
    "        \"\"\"\n",
    "        http://en.wikipedia.org/wiki/Shallow_water_equations#Non-conservative_form\n",
    "        \"\"\"\n",
    "        for x in [h, u, v]: # type check\n",
    "           assert isinstance(x, np.ndarray) and not isinstance(x, np.matrix)\n",
    "\n",
    "        g,b,dx = self.g, self.b, self.dx\n",
    "\n",
    "        du_dt = -g*self.d_dx(h) - b*u\n",
    "        dv_dt = -g*self.d_dy(h) - b*v\n",
    "\n",
    "        H = 0 #h.mean() - our definition of h includes this term\n",
    "        dh_dt = -self.d_dx(u * (H+h)) - self.d_dy(v * (H+h))\n",
    "\n",
    "        return dh_dt, du_dt, dv_dt\n",
    "\n",
    "\n",
    "    def evolve(self):\n",
    "        \"\"\"\n",
    "        Evolve state (h, u, v) forward in time using simple Euler method\n",
    "        x_{N+1} = x_{N} +   dx/dt * d_t\n",
    "        \"\"\"\n",
    "\n",
    "        dh_dt, du_dt, dv_dt = self.d_dt(self.h, self.u, self.v)\n",
    "        dt = self.dt\n",
    "\n",
    "        self.h += dh_dt * dt\n",
    "        self.u += du_dt * dt\n",
    "        self.v += dv_dt * dt\n",
    "        self.time += dt\n",
    "\n",
    "        return self.h, self.u, self.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "def simu(iteration_times, Hp, R, n_steps,blank_steps, px, py):\n",
    "    SW = shallow(N=64, px=px, py=py, R=R, Hp=Hp, b=0.2)\n",
    "    num = (iteration_times - blank_steps) // n_steps\n",
    "    true_u_vect = np.zeros((num, SW.N, SW.N))\n",
    "    true_v_vect = np.zeros((num, SW.N, SW.N))\n",
    "    true_h_vect = np.zeros((num, SW.N, SW.N))\n",
    "    index = 0\n",
    "\n",
    "    for i in range(iteration_times):\n",
    "        SW.evolve()\n",
    "\n",
    "        if i % n_steps == 0 and i >= 500:\n",
    "            true_u_vect[index], true_v_vect[index], true_h_vect[index] = SW.u, SW.v, SW.h\n",
    "            index += 1\n",
    "\n",
    "    return true_u_vect, true_v_vect, true_h_vect\n",
    "\n",
    "\n",
    "def structure_obs(N, random_range):\n",
    "    x = np.arange(0, N, 7)\n",
    "    y = np.arange(0, N, 7)\n",
    "    x_list, y_list = np.meshgrid(x, y)\n",
    "\n",
    "    x_coord = np.empty(x_list.size, dtype=int)\n",
    "    y_coord = np.empty(y_list.size, dtype=int)\n",
    "\n",
    "    for i, (x_val, y_val) in enumerate(zip(x_list.flatten(), y_list.flatten())):\n",
    "        if (i+1) % 64 != 0:\n",
    "            x_val += rand.randint(0, random_range)\n",
    "            y_val += rand.randint(0, random_range)\n",
    "\n",
    "        x_coord[i] = x_val if x_val < N else N - 1\n",
    "        y_coord[i] = y_val if y_val < N else N - 1\n",
    "\n",
    "    return x_coord, y_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(112)\n",
    "second_element_range = (0.2, 0.8)\n",
    "third_element_range = (4, 12)\n",
    "\n",
    "# Number of random tuples to generate\n",
    "num_random_tuples = 50\n",
    "steps = 3500\n",
    "blank_steps = 500\n",
    "px = 32\n",
    "py = 32\n",
    "# Generate random tuples\n",
    "sim_params = [(steps,\n",
    "               round(random.uniform(*second_element_range), 2),\n",
    "               random.randint(*third_element_range),\n",
    "               10,\n",
    "               blank_steps,\n",
    "               px,#np.random.randint(30, 34),  # px\n",
    "               py)#random.randint(30, 34))  # py\n",
    "              for _ in range(num_random_tuples)]\n",
    "# Simulate data and stack the results\n",
    "def simulate_and_stack(sim_params):\n",
    "    true_u_vect, true_v_vect, true_h_vect = [], [], []\n",
    "    for nsteps, hp, r, n,blank,px,py in sim_params:\n",
    "        u, v, h = simu(nsteps, hp, r**2, n,blank,px,py)\n",
    "        true_u_vect.append(u)\n",
    "        true_v_vect.append(v)\n",
    "        true_h_vect.append(h)\n",
    "\n",
    "    true_u_vect = np.vstack(true_u_vect)\n",
    "    true_v_vect = np.vstack(true_v_vect)\n",
    "    true_h_vect = np.vstack(true_h_vect)\n",
    "\n",
    "    return true_u_vect, true_v_vect, true_h_vect\n",
    "\n",
    "# Simulate data and stack the results\n",
    "true_u_vect, true_v_vect, true_h_vect = simulate_and_stack(sim_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract data for train_params\n",
    "second_elements_train = [param[1] for param in train_params]\n",
    "third_elements_train = [param[2] for param in train_params]\n",
    "df_train = pd.DataFrame(list(zip(second_elements_train, third_elements_train)), columns=['Second Element', 'Third Element'])\n",
    "frequency_train = df_train.groupby(['Second Element', 'Third Element']).size().reset_index(name='Frequency')\n",
    "x_train = frequency_train['Second Element']\n",
    "y_train = frequency_train['Third Element']\n",
    "\n",
    "# Extract data for test_params\n",
    "second_elements_test = [param[1] for param in test_params]\n",
    "third_elements_test = [param[2] for param in test_params]\n",
    "df_test = pd.DataFrame(list(zip(second_elements_test, third_elements_test)), columns=['Second Element', 'Third Element'])\n",
    "frequency_test = df_test.groupby(['Second Element', 'Third Element']).size().reset_index(name='Frequency')\n",
    "x_test = frequency_test['Second Element']\n",
    "y_test = frequency_test['Third Element']\n",
    "\n",
    "# Set up the figure and axes for side-by-side plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot for train_params\n",
    "scatter1 = ax1.scatter(x_train, y_train, c='turquoise', edgecolor='black', s=150, alpha=0.75)\n",
    "ax1.set_xlabel('Water Height (m)', fontsize=12)\n",
    "ax1.set_ylabel('Radius (grid unit)', fontsize=12)\n",
    "ax1.set_title('Training Parameter Combinations', fontsize=14)\n",
    "ax1.grid(True, linestyle='--')\n",
    "ax1.set_facecolor('whitesmoke')\n",
    "\n",
    "# Plot for test_params\n",
    "scatter2 = ax2.scatter(x_test, y_test, c='purple', edgecolor='black', s=150, alpha=0.75)\n",
    "ax2.set_xlabel('Water Height (m)', fontsize=12)\n",
    "ax2.set_ylabel('Radius (grid unit)', fontsize=12)\n",
    "ax2.set_title('Testing Parameter Combinations', fontsize=14)\n",
    "ax2.grid(True, linestyle='--')\n",
    "ax2.set_facecolor('whitesmoke')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./Dataset_sw/true_u_full.npy',true_u_vect)\n",
    "np.save('./Dataset_sw/true_v_full.npy',true_v_vect)\n",
    "np.save('./Dataset_sw/true_h_full.npy',true_h_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_u_vect = np.load('/content/drive/MyDrive/Physics/Physics/Dataset10/true_u_full.npy', mmap_mode=\"r\")\n",
    "true_v_vect = np.load('/content/drive/MyDrive/Physics/Physics/Dataset10/true_v_full.npy', mmap_mode=\"r\")\n",
    "true_h_vect = np.load('/content/drive/MyDrive/Physics/Physics/Dataset10/true_h_full.npy', mmap_mode=\"r\")\n",
    "\n",
    "a = 50*300\n",
    "\n",
    "\n",
    "# Constants\n",
    "N = 64\n",
    "datasize = int(a)  # Ensure 'a' is defined earlier in your code\n",
    "\n",
    "# Initialize arrays\n",
    "true_data = np.zeros((datasize, N, N, 3))  # Combining u, v, h data into one array for simplicity\n",
    "vor_data = np.zeros((datasize, N, N, 3))\n",
    "\n",
    "# Grid preparation\n",
    "x, y = np.linspace(0., N, N), np.linspace(0., N, N)[::-1]\n",
    "X, Y = np.meshgrid(x, y)\n",
    "P = np.column_stack((X.flatten(), Y.flatten()))\n",
    "\n",
    "# Data processing and conditional plotting\n",
    "for index in range(datasize):\n",
    "    for vect, slice_idx in zip([true_u_vect, true_v_vect, true_h_vect], range(3)):\n",
    "        x_coord, y_coord = structure_obs(64, 2)\n",
    "        Zi = vect[index, x_coord.astype(int), N-1-y_coord.astype(int)]\n",
    "        Pi = np.column_stack((x_coord, y_coord))\n",
    "        Z_nearest = griddata(Pi, Zi, P, method=\"nearest\").reshape([N, N])\n",
    "        vor_data[index, :, :, slice_idx] = Z_nearest\n",
    "        true_data[index, :, :, slice_idx] = vect[index, :, :]\n",
    "\n",
    "# Correcting the data swap issue\n",
    "vor_u_data, vor_v_data = vor_data[..., 0], vor_data[..., 1]\n",
    "vor_h_data, true_u_data = vor_data[..., 2], true_data[..., 0]\n",
    "true_v_data, true_h_data = true_data[..., 1], true_data[..., 2]\n",
    "\n",
    "np.save('./Dataset_sw/vor_u_full.npy', vor_u_data)\n",
    "np.save('./Dataset_sw/vor_v_full.npy', vor_v_data)\n",
    "np.save('.Dataset_sw/vor_h_full.npy', vor_h_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vor_u_data = np.load('./Dataset_sw/vor_u_full.npy', mmap_mode=\"r\")\n",
    "vor_v_data = np.load('./Dataset_sw/vor_v_full.npy', mmap_mode=\"r\")\n",
    "vor_h_data = np.load('./Dataset_sw/vor_h_full.npy', mmap_mode=\"r\")\n",
    "true_v_data = np.load('./Dataset_sw/true_v_full.npy', mmap_mode=\"r\")\n",
    "true_u_data = np.load('./Dataset_sw/true_u_full.npy', mmap_mode=\"r\")\n",
    "true_h_data = np.load('./Dataset_sw/true_h_full.npy', mmap_mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasize = 50 * 300\n",
    "train_rate = 0.80\n",
    "\n",
    "# Directly calculate train and test sizes\n",
    "train_size = int(datasize * train_rate)\n",
    "test_size = datasize - train_size\n",
    "\n",
    "# Data categories and datasets\n",
    "data_types = ['u', 'v', 'h']\n",
    "voronoi_data = [vor_u_data, vor_v_data, vor_h_data]\n",
    "true_data = [true_v_data, true_u_data, true_h_data] \n",
    "\n",
    "def split_data(data, train_size):\n",
    "    return data[:train_size], data[train_size:]\n",
    "\n",
    "vor_train, vor_test = zip(*[split_data(data, train_size) for data in voronoi_data])\n",
    "true_train, true_test = zip(*[split_data(data, train_size) for data in true_data])\n",
    "\n",
    "vor_train = np.stack(vor_train, axis=-1)\n",
    "true_train = np.stack(true_train, axis=-1)\n",
    "vor_test = np.stack(vor_test, axis=-1)\n",
    "true_test = np.stack(true_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './Dataset_sw/'\n",
    "\n",
    "# Save the arrays to disk\n",
    "np.save(save_path + 'vor_train.npy', vor_train)\n",
    "np.save(save_path + 'true_train.npy', true_train)\n",
    "np.save(save_path + 'vor_test.npy', vor_test)\n",
    "np.save(save_path + 'true_test.npy', true_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
